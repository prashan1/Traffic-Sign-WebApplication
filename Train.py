# -*- coding: utf-8 -*-
"""Traffic Sign Recognition

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15FsEyihvbhRNCuRhwEtIvsM9sMngRE96

# Cloning our data
"""

!git clone https://bitbucket.org/jadslim/german-traffic-signs

!ls german-traffic-signs

import pickle 
import pandas as pd, numpy as np , matplotlib.pyplot as plt
import tensorflow as tf
import cv2, random

"""## Unzipping our dataset"""

with open("/content/german-traffic-signs/train.p", mode = 'rb') as training_data:
  train = pickle.load(training_data)

with open("/content/german-traffic-signs/test.p", mode = 'rb') as testt:
  test = pickle.load(testt)

with open("/content/german-traffic-signs/valid.p", mode = 'rb') as validd:
  valid = pickle.load(validd)

train.items()

"""## Splitting our dataset"""

X_train , Y_train = train['features'] , train['labels']
x_valid , y_valid = valid['features'] , valid['labels']
x_test , y_test = test['features'] , test['labels']

"""## Visualizig the dataset"""

print('Shape of our training data -> ', X_train.shape)
print('Shape of our validation data -> ', x_valid.shape)
print('Shape of our testing data -> ', x_test.shape)

data = pd.read_csv('/content/german-traffic-signs/signnames.csv')
fig, axs = plt.subplots(nrows=43, ncols=5, figsize=(5,50))
fig.tight_layout()
distribution = []
for i in range(43):
  n , sign = data.loc[i,:]
  for j  in range(5):
    currentdf = X_train[ Y_train == n ]
    img = random.choice(currentdf)
    axs[i][j].imshow(img , cmap=plt.get_cmap('gray'))
    axs[i][j].axis('off')
    if j == 2 :
      axs[i][j].set_title(str(i) + ' - ' + sign )
  distribution.append(len(X_train[Y_train==n]))

plt.figure(figsize=(12,4))
plt.bar(range(0,43),distribution)
plt.xlabel('Classes')
plt.ylabel('Number of image')
plt.title('Distribution of data')
plt.show()

"""## Image preprocessing
#1 - Changing to Grayscale for fast computation
#2 - Equalizing the contrast of every image
#3 - Normalizing our image for fast computation
"""

def rgb2G( img ):
  img= cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)
  return img
def equalize( img ):
  img = cv2.equalizeHist(img)
  return img

plt.imshow( train['features'][55] )
plt.show()

img = plt.imshow( rgb2G(train['features'][55])  )
plt.show()

def preprocessing( img ):
  img = equalize( rgb2G( img ) )
  img = img/255.
  return img

X_train = list(map(preprocessing , X_train))
x_valid = list(map(preprocessing , x_valid))
x_test = list(map(preprocessing , x_test))

X_train = np.array(X_train).reshape(34799,32,32,1)
x_valid = np.array(x_valid).reshape(4410,32,32,1)
X_test = np.array(x_test).reshape(12630,32,32,1)

Y_train = tf.keras.utils.to_categorical(Y_train, 43)
y_test = tf.keras.utils.to_categorical(y_test, 43)
y_valid = tf.keras.utils.to_categorical(y_valid, 43)

"""## Designing our model"""

model = tf.keras.models.Sequential([
                                    
                tf.keras.layers.Conv2D(60,(5,5),input_shape=(32,32,1) , activation = 'relu'),
                tf.keras.layers.Conv2D(60,(5,5),activation = 'relu'),
                tf.keras.layers.MaxPooling2D((2,2)),

                tf.keras.layers.Conv2D(30,(3,3), activation = 'relu'),
                tf.keras.layers.Conv2D(30,(3,3),activation = 'relu'),
                tf.keras.layers.MaxPooling2D((2,2)),

                tf.keras.layers.Flatten(),
                tf.keras.layers.Dense(500, activation = 'relu'),
                tf.keras.layers.Dropout(0.5),
                tf.keras.layers.Dense(43,activation = 'softmax')

])

model.summary()

model.compile(metrics = ['accuracy'] , optimizer = tf.keras.optimizers.Adam(lr = 0.001) , loss = 'categorical_crossentropy')

"""## Creating a DataGenerator for generating different data per epoch"""

datagen = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=0.1,
                            height_shift_range=0.1,
                            zoom_range=0.2,
                            shear_range=0.1,
                            rotation_range=10.)
batches = datagen.flow(X_train, Y_train, batch_size = 15)
X_batch, Y_batch = next(batches)
 
fig, axs = plt.subplots(1, 15, figsize=(20, 5))
fig.tight_layout()
 
for i in range(15):
    axs[i].imshow(X_batch[i].reshape(32, 32))
    axs[i].axis("off")
 
print(X_batch.shape)

history = model.fit_generator( datagen.flow(X_train,Y_train,batch_size = 50 )
    ,steps_per_epoch=34799/50,
    validation_data = (x_valid , y_valid),
    epochs = 15,
    verbose = 1,
    )

axes = plt.gca()
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
axes.set_xlim([0.0,17.5])
axes.set_ylim([0.0,0.8])
plt.title('Loss')
plt.xlabel('epoch')

axes = plt.gca()
axes.set_xlim([0.0,17.5])
axes.set_ylim([0.30,1.00])
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['training','test'])
plt.title('Accuracy')
plt.xlabel('epoch')
plt.style.use('ggplot')

"""## Testing our model"""

import requests
from PIL import Image
url = 'https://thumbs.dreamstime.com/t/road-signs-main-road-sign-blue-background-road-signs-main-road-sign-blue-background-109436823.jpg'
r = requests.get(url, stream=True)
img = Image.open(r.raw)
plt.imshow(img, cmap=plt.get_cmap('gray'))

img = np.array(img)
img = cv2.resize(img , (32,32))
img = preprocessing( img )
img = np.array(img).reshape(1,32,32,1)

print('The photo belong to ', data.loc[model.predict_classes(img)[0],:][1] , ' class')

"""## Testing on test set"""

prediction = model.predict_classes(X_test)

from sklearn.metrics import accuracy_score
accuracy_score(prediction , test['labels'])

model.save('weights.h5')

